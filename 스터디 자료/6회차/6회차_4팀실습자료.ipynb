{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6회차_14장_실습코드.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX62Pyz7-XeN"
      },
      "source": [
        "## 14장 베스트모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfochqS1-Xsj"
      },
      "source": [
        "import numpy as np \r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint # 추가!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9GBLIxl-H2R"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPC8fS4TwZd9"
      },
      "source": [
        "np.random.seed(3)\r\n",
        "tf.random.set_seed(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_UmvoOw-RI5"
      },
      "source": [
        "df_pre = pd.read_csv(\"wine.csv\",header=None)\r\n",
        "df = df_pre.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOuPQ5xs-4nj"
      },
      "source": [
        "dataset= df.values\r\n",
        "X = dataset[:,0:12]\r\n",
        "Y = dataset[:,12]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPyJiP_qA5e3"
      },
      "source": [
        "#모델 설정\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(30,input_dim = 12,activation='relu'))\r\n",
        "model.add(Dense(12,activation='relu'))\r\n",
        "model.add(Dense(8,activation='relu'))\r\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn2CdGnAIBa6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQRHYGf2xDV9"
      },
      "source": [
        "# 모델 컴파일\r\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr0hUxQYv9Gk"
      },
      "source": [
        "모델 업데이트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO9gmQ2YBCd2",
        "outputId": "1c3ece20-76ed-42e8-f1d8-854ee8ddeda7"
      },
      "source": [
        "#모델 저장 폴더 설정\r\n",
        "import os\r\n",
        "MODEL_DIR = './model/'\r\n",
        "if not os.path.exists(MODEL_DIR): # 없으면 폴더 생성 / 새로고침하면 생성되어있음 확인\r\n",
        "  os.mkdir(MODEL_DIR)\r\n",
        "\r\n",
        "#모델 저장 조건 설정\r\n",
        "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\r\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss',verbose=1,save_best_only=True)\r\n",
        "\r\n",
        "#모델 실행 및 저장\r\n",
        "model.fit(X,Y,epochs=200,validation_split=0.2,batch_size=200,verbose=0, callbacks=[checkpointer])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.38706, saving model to ./model/01-0.3871.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.38706 to 0.28561, saving model to ./model/02-0.2856.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.28561 to 0.24630, saving model to ./model/03-0.2463.hdf5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.24630 to 0.23385, saving model to ./model/04-0.2338.hdf5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.23385 to 0.22901, saving model to ./model/05-0.2290.hdf5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.22901 to 0.22135, saving model to ./model/06-0.2214.hdf5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.22135 to 0.21528, saving model to ./model/07-0.2153.hdf5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.21528 to 0.20855, saving model to ./model/08-0.2086.hdf5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.20855 to 0.19963, saving model to ./model/09-0.1996.hdf5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.19963 to 0.19792, saving model to ./model/10-0.1979.hdf5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.19792 to 0.18896, saving model to ./model/11-0.1890.hdf5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.18896 to 0.18506, saving model to ./model/12-0.1851.hdf5\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.18506 to 0.18127, saving model to ./model/13-0.1813.hdf5\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.18127 to 0.17801, saving model to ./model/14-0.1780.hdf5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.17801 to 0.17631, saving model to ./model/15-0.1763.hdf5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.17631 to 0.17160, saving model to ./model/16-0.1716.hdf5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.17160 to 0.16956, saving model to ./model/17-0.1696.hdf5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.16956 to 0.16680, saving model to ./model/18-0.1668.hdf5\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.16680 to 0.16383, saving model to ./model/19-0.1638.hdf5\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.16383 to 0.16313, saving model to ./model/20-0.1631.hdf5\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.16313 to 0.15975, saving model to ./model/21-0.1597.hdf5\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.15975 to 0.15546, saving model to ./model/22-0.1555.hdf5\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.15546 to 0.15327, saving model to ./model/23-0.1533.hdf5\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.15327 to 0.15144, saving model to ./model/24-0.1514.hdf5\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.15144 to 0.14768, saving model to ./model/25-0.1477.hdf5\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.14768 to 0.14690, saving model to ./model/26-0.1469.hdf5\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.14690 to 0.14301, saving model to ./model/27-0.1430.hdf5\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.14301\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.14301\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.14301 to 0.13609, saving model to ./model/30-0.1361.hdf5\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.13609 to 0.13560, saving model to ./model/31-0.1356.hdf5\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.13560\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.13560 to 0.13057, saving model to ./model/33-0.1306.hdf5\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.13057\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.13057\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.13057 to 0.12732, saving model to ./model/36-0.1273.hdf5\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.12732 to 0.12037, saving model to ./model/37-0.1204.hdf5\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.12037 to 0.11840, saving model to ./model/38-0.1184.hdf5\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.11840 to 0.11774, saving model to ./model/39-0.1177.hdf5\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.11774 to 0.10965, saving model to ./model/40-0.1096.hdf5\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.10965 to 0.10570, saving model to ./model/41-0.1057.hdf5\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.10570 to 0.10178, saving model to ./model/42-0.1018.hdf5\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.10178 to 0.10058, saving model to ./model/43-0.1006.hdf5\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.10058 to 0.09882, saving model to ./model/44-0.0988.hdf5\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.09882\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.09882\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.09882 to 0.09384, saving model to ./model/47-0.0938.hdf5\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.09384 to 0.09168, saving model to ./model/48-0.0917.hdf5\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.09168\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.09168 to 0.08930, saving model to ./model/50-0.0893.hdf5\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.08930\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.08930 to 0.08578, saving model to ./model/52-0.0858.hdf5\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.08578\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.08578\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.08578 to 0.08391, saving model to ./model/55-0.0839.hdf5\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.08391\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.08391\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.08391\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.08391\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.08391 to 0.08097, saving model to ./model/60-0.0810.hdf5\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.08097 to 0.07689, saving model to ./model/61-0.0769.hdf5\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.07689 to 0.07604, saving model to ./model/62-0.0760.hdf5\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.07604\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.07604\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.07604 to 0.07245, saving model to ./model/65-0.0725.hdf5\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.07245\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.07245\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.07245\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.07245\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.07245\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.07245\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.07245 to 0.06785, saving model to ./model/72-0.0679.hdf5\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.06785\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.06785 to 0.06785, saving model to ./model/74-0.0679.hdf5\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.06785 to 0.06619, saving model to ./model/75-0.0662.hdf5\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.06619 to 0.06607, saving model to ./model/76-0.0661.hdf5\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.06607 to 0.06482, saving model to ./model/77-0.0648.hdf5\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.06482 to 0.06456, saving model to ./model/78-0.0646.hdf5\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.06456\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.06456\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.06456\n",
            "\n",
            "Epoch 00082: val_loss improved from 0.06456 to 0.06392, saving model to ./model/82-0.0639.hdf5\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.06392 to 0.06284, saving model to ./model/83-0.0628.hdf5\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.06284\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.06284\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.06284\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.06284 to 0.06094, saving model to ./model/87-0.0609.hdf5\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.06094 to 0.05994, saving model to ./model/88-0.0599.hdf5\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.05994\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.05994\n",
            "\n",
            "Epoch 00091: val_loss improved from 0.05994 to 0.05883, saving model to ./model/91-0.0588.hdf5\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.05883 to 0.05867, saving model to ./model/92-0.0587.hdf5\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.05867\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.05867 to 0.05855, saving model to ./model/94-0.0585.hdf5\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.05855\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.05855\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.05855\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.05855 to 0.05748, saving model to ./model/98-0.0575.hdf5\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.05748 to 0.05683, saving model to ./model/99-0.0568.hdf5\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.05683\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.05683\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.05683\n",
            "\n",
            "Epoch 00103: val_loss improved from 0.05683 to 0.05634, saving model to ./model/103-0.0563.hdf5\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.05634\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.05634\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.05634\n",
            "\n",
            "Epoch 00107: val_loss improved from 0.05634 to 0.05610, saving model to ./model/107-0.0561.hdf5\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.05610\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.05610 to 0.05572, saving model to ./model/109-0.0557.hdf5\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.05572\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.05572\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.05572\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.05572\n",
            "\n",
            "Epoch 00114: val_loss improved from 0.05572 to 0.05500, saving model to ./model/114-0.0550.hdf5\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.05500\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.05500\n",
            "\n",
            "Epoch 00117: val_loss improved from 0.05500 to 0.05463, saving model to ./model/117-0.0546.hdf5\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.05463\n",
            "\n",
            "Epoch 00119: val_loss improved from 0.05463 to 0.05369, saving model to ./model/119-0.0537.hdf5\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.05369\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.05369\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.05369 to 0.05363, saving model to ./model/122-0.0536.hdf5\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.05363\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.05363 to 0.05296, saving model to ./model/124-0.0530.hdf5\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.05296\n",
            "\n",
            "Epoch 00139: val_loss improved from 0.05296 to 0.05273, saving model to ./model/139-0.0527.hdf5\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.05273\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.05273\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.05273\n",
            "\n",
            "Epoch 00143: val_loss improved from 0.05273 to 0.05197, saving model to ./model/143-0.0520.hdf5\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.05197\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.05197\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.05197\n",
            "\n",
            "Epoch 00147: val_loss improved from 0.05197 to 0.05146, saving model to ./model/147-0.0515.hdf5\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.05146\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.05146\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.05146\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.05146\n",
            "\n",
            "Epoch 00152: val_loss improved from 0.05146 to 0.05134, saving model to ./model/152-0.0513.hdf5\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.05134\n",
            "\n",
            "Epoch 00167: val_loss improved from 0.05134 to 0.05104, saving model to ./model/167-0.0510.hdf5\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.05104\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.05104\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.05104\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.05104\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.05104\n",
            "\n",
            "Epoch 00173: val_loss improved from 0.05104 to 0.04913, saving model to ./model/173-0.0491.hdf5\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.04913\n",
            "\n",
            "Epoch 00190: val_loss improved from 0.04913 to 0.04864, saving model to ./model/190-0.0486.hdf5\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.04864\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.04864\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.04864\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.04864\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.04864\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.04864\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.04864\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.04864\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.04864\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.04864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f971a34db38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvtFqUJWC2R3"
      },
      "source": [
        "#### 오버피팅 방지 - 학습의 자동중단\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l94-M8Z9CfP2"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(24,input_dim = 12,activation='relu'))\r\n",
        "model.add(Dense(12,activation='relu'))\r\n",
        "model.add(Dense(1,activation='sigmoid'))\r\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\r\n",
        "checkPointer = ModelCheckpoint(filepath=model_path,monitor='val_loss',verbose=0,save_best_only=True)\r\n",
        "\r\n",
        "hist = model.fit(x_data,y_data,epochs=2000,validation_split=0.2,batch_size=1280,verbose=0,\r\n",
        "          callbacks=[checkPointer]) #validation set!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "RGd0KXo2FHv7",
        "outputId": "f9adac18-2afe-40a0-e11f-7c383f19800f"
      },
      "source": [
        "y_vloss = hist.history['val_loss']\r\n",
        "y_acc = hist.history['accuracy']\r\n",
        "\r\n",
        "x_len = np.arange(len(y_acc))\r\n",
        "plt.grid(True)\r\n",
        "plt.plot(x_len,y_vloss, \"ro\")\r\n",
        "plt.plot(x_len,y_acc,\"bo\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9cab8d4198>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXgL43Z2Gf9n"
      },
      "source": [
        "## 13 14 장 내용의 종합 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpwrVXkOGxSO"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold as SKfold\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "n_fold = 5 # 5겹 \r\n",
        "skf = SKfold(n_splits=n_fold,shuffle=True,random_state=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hQYNJBTFktE"
      },
      "source": [
        "data = pd.read_csv(\"wine.csv\",header=None)\r\n",
        "x_data = data.iloc[:,:-1]\r\n",
        "y_data = data.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95XPMFgXGrUf",
        "outputId": "8ae4dff1-e550-47a9-e643-d28ea0c43972"
      },
      "source": [
        "\r\n",
        "accuracy = []\r\n",
        "i = 1 \r\n",
        "for train,test in skf.split(x_data,y_data):\r\n",
        "  # 모델 쌓기\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Dense(32,input_dim = 12,activation='relu'))\r\n",
        "  model.add(Dense(16,activation='relu'))\r\n",
        "  model.add(Dense(8,activation='relu'))\r\n",
        "  model.add(Dense(1,activation='sigmoid'))\r\n",
        "\r\n",
        "  # 모델 컴파일\r\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\r\n",
        "  early_stop = EarlyStopping(monitor='val_loss',patience=100,verbose=1)\r\n",
        "\r\n",
        "  # 모델 실행\r\n",
        "  model.fit(x_data.iloc[train],y_data[train],epochs=1000,batch_size=256,\r\n",
        "            validation_split=0.1,callbacks=[early_stop],verbose = 0) # 쪼개진 train set 에서 또 0.2 정도를 나눔\r\n",
        "  # validation set 으로 early stop을 결정 \r\n",
        "\r\n",
        "  # 검증은 테스트 셋으로\r\n",
        "  Kth_accuracy = '%.4f'%(model.evaluate(x_data.iloc[test],y_data[test])[1]) # 쪼개진 테스트 데이터로 검증\r\n",
        "  print(\"%d 번째 fold :\"%(i),Kth_accuracy)\r\n",
        "  i+=1\r\n",
        "  accuracy.append(Kth_accuracy)\r\n",
        "\r\n",
        "\r\n",
        "# 교차 검증 평가\r\n",
        "print(accuracy)\r\n",
        "print(\"평균:\",np.mean(np.array(accuracy).astype(float)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 00205: early stopping\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9846\n",
            "1 번째 fold : 0.9846\n",
            "Epoch 00201: early stopping\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9815\n",
            "2 번째 fold : 0.9815\n",
            "Epoch 00102: early stopping\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9769\n",
            "3 번째 fold : 0.9769\n",
            "Epoch 00317: early stopping\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9846\n",
            "4 번째 fold : 0.9846\n",
            "Epoch 00327: early stopping\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9869\n",
            "5 번째 fold : 0.9869\n",
            "['0.9846', '0.9815', '0.9769', '0.9846', '0.9869']\n",
            "평균: 0.9829000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElHZ71QXKBmg"
      },
      "source": [
        "[Train , Test , Validation set 차이](https://ganghee-lee.tistory.com/38)\r\n",
        "\r\n",
        "kfold 로 Train ,test 로 나눠서  train으로 학습, test로 평가\r\n",
        "\r\n",
        "나눠진 train 으로 train/validation 으로 또 나눔 (validataion_split)\r\n",
        "\r\n",
        "이 나눠진 validataion set 으로 \r\n",
        "\r\n",
        "validation_loss 를 모니터링하여 \r\n",
        "\r\n",
        "early stopping 여부를 결정"
      ]
    }
  ]
}